{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 file \"greenbeans.h5\" (mode r)>\n",
      "├── algo\n",
      "│   ├── key (scalar)\n",
      "│   └── processor_config (scalar)\n",
      "├── client_info (scalar)\n",
      "├── generation (scalar)\n",
      "├── lib_version (scalar)\n",
      "├── server_info (scalar)\n",
      "├── session\n",
      "│   ├── calibrations\n",
      "│   │   └── sensor_1\n",
      "│   │       ├── data (scalar)\n",
      "│   │       ├── provided (scalar)\n",
      "│   │       └── temperature (scalar)\n",
      "│   ├── group_0\n",
      "│   │   └── entry_0\n",
      "│   │       ├── metadata (scalar)\n",
      "│   │       ├── result\n",
      "│   │       │   ├── calibration_needed (65763)\n",
      "│   │       │   ├── data_saturated (65763)\n",
      "│   │       │   ├── frame (65763)\n",
      "│   │       │   ├── frame_delayed (65763)\n",
      "│   │       │   ├── temperature (65763)\n",
      "│   │       │   └── tick (65763)\n",
      "│   │       └── sensor_id (scalar)\n",
      "│   └── session_config (scalar)\n",
      "├── sessions\n",
      "│   └── session_0\n",
      "│       ├── calibrations\n",
      "│       │   └── sensor_1\n",
      "│       │       ├── data (scalar)\n",
      "│       │       ├── provided (scalar)\n",
      "│       │       └── temperature (scalar)\n",
      "│       ├── group_0\n",
      "│       │   └── entry_0\n",
      "│       │       ├── metadata (scalar)\n",
      "│       │       ├── result\n",
      "│       │       │   ├── calibration_needed (65763)\n",
      "│       │       │   ├── data_saturated (65763)\n",
      "│       │       │   ├── frame (65763)\n",
      "│       │       │   ├── frame_delayed (65763)\n",
      "│       │       │   ├── temperature (65763)\n",
      "│       │       │   └── tick (65763)\n",
      "│       │       └── sensor_id (scalar)\n",
      "│       └── session_config (scalar)\n",
      "├── timestamp (scalar)\n",
      "└── uuid (scalar)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "filename_hdf = 'data/greenbeans.h5'\n",
    "\n",
    "def h5_tree(val, pre=''):\n",
    "    items = len(val)\n",
    "    for key, val in val.items():\n",
    "        items -= 1\n",
    "        if items == 0:\n",
    "            # the last item\n",
    "            if type(val) == h5py._hl.group.Group:\n",
    "                print(pre + '└── ' + key)\n",
    "                h5_tree(val, pre+'    ')\n",
    "            else:\n",
    "                try:\n",
    "                    print(pre + '└── ' + key + ' (%d)' % len(val))\n",
    "                except TypeError:\n",
    "                    print(pre + '└── ' + key + ' (scalar)')\n",
    "        else:\n",
    "            if type(val) == h5py._hl.group.Group:\n",
    "                print(pre + '├── ' + key)\n",
    "                h5_tree(val, pre+'│   ')\n",
    "            else:\n",
    "                try:\n",
    "                    print(pre + '├── ' + key + ' (%d)' % len(val))\n",
    "                except TypeError:\n",
    "                    print(pre + '├── ' + key + ' (scalar)')\n",
    "\n",
    "with h5py.File(filename_hdf, 'r') as hf:\n",
    "    print(hf)\n",
    "    h5_tree(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def extract_tensor_from_h5(file_path, dataset_path):\n",
    "    \"\"\"\n",
    "    Extracts a tensor from an H5 file and checks for non-numerical data.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, path to the H5 file\n",
    "    - dataset_path: str, path to the dataset within the H5 file\n",
    "\n",
    "    Returns:\n",
    "    - tensor: numpy.ndarray, the extracted tensor if purely numerical\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as h5file:\n",
    "        if dataset_path in h5file:\n",
    "            dataset = h5file[dataset_path]\n",
    "            tensor = np.array(dataset)\n",
    "\n",
    "            return tensor\n",
    "        else:\n",
    "            raise KeyError(f\"Dataset {dataset_path} not found in the file {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10, 200)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset_path = 'session/group_0/entry_0/result/frame'\n",
    "\n",
    "def load_and_convert_tensor(file_path):\n",
    "    # Extract tensor from HDF5 file\n",
    "    tensor = extract_tensor_from_h5(file_path, dataset_path)\n",
    "\n",
    "    # Convert to complex number\n",
    "    complex_tensor = tensor['real'] + 1j * tensor['imag']\n",
    "\n",
    "    return complex_tensor\n",
    "\n",
    "def preprocess_data(complex_tensor):\n",
    "    # Separate real and imaginary parts\n",
    "    real_part = complex_tensor.real.astype(np.float32)\n",
    "    imag_part = complex_tensor.imag.astype(np.float32)\n",
    "\n",
    "    # Combine into a single input array (concatenation along the last axis)\n",
    "    combined_input = np.concatenate([real_part, imag_part], axis=-1)\n",
    "\n",
    "    return combined_input\n",
    "\n",
    "# def preprocess_data(complex_tensor):\n",
    "#     # Compute magnitude and phase\n",
    "#     magnitude = np.abs(complex_tensor).astype(np.float32)\n",
    "#     phase = np.angle(complex_tensor).astype(np.float32)\n",
    "\n",
    "#     # Combine into a single input array (concatenation along the last axis)\n",
    "#     combined_input = np.concatenate([magnitude, phase], axis=-1)\n",
    "\n",
    "#     return combined_input\n",
    "\n",
    "bean_names = (\"colombia\", \"kenya\", \"peru\", \"sumatra\", \"tabi\")\n",
    "\n",
    "bean_tensors = [\n",
    "    [preprocess_data(load_and_convert_tensor(f\"new-test-setup/{bean}-458-{run}.h5\")) for run in range(1, 11)]\n",
    "                for bean in bean_names]\n",
    "\n",
    "for i in range(len(bean_tensors)):\n",
    "    for j in range(len(bean_tensors[0])):\n",
    "        bean_tensors[i][j] = np.squeeze(np.mean(bean_tensors[i][j], axis=0))\n",
    "\n",
    "bean_tensors = np.array(bean_tensors)\n",
    "bean_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 200)\n"
     ]
    }
   ],
   "source": [
    "num_classes = bean_tensors.shape[0]\n",
    "num_samples_per_class = bean_tensors.shape[1]\n",
    "num_points_per_sample = bean_tensors.shape[2]\n",
    "\n",
    "bean_tensors = bean_tensors.reshape(-1, num_points_per_sample)\n",
    "print(bean_tensors.shape)\n",
    "\n",
    "bean_labels = np.array([i for i in range(num_classes) for _ in range(num_samples_per_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (40, 200)\n",
      "Testing data shape: (10, 200)\n",
      "Epoch 1/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2134 - loss: 1828.9514 - val_accuracy: 0.2000 - val_loss: 801.0704\n",
      "Epoch 2/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1412 - loss: 176.2308 - val_accuracy: 0.0000e+00 - val_loss: 704.6458\n",
      "Epoch 3/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3197 - loss: 203.1598 - val_accuracy: 0.2000 - val_loss: 612.4860\n",
      "Epoch 4/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2255 - loss: 164.8260 - val_accuracy: 0.0000e+00 - val_loss: 559.2045\n",
      "Epoch 5/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1828 - loss: 17.2498 - val_accuracy: 0.0000e+00 - val_loss: 545.6474\n",
      "Epoch 6/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2232 - loss: 55.4226 - val_accuracy: 0.0000e+00 - val_loss: 526.3627\n",
      "Epoch 7/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2402 - loss: 49.9910 - val_accuracy: 0.0000e+00 - val_loss: 582.3686\n",
      "Epoch 8/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2016 - loss: 95.2651 - val_accuracy: 0.1000 - val_loss: 531.8238\n",
      "Epoch 9/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1977 - loss: 61.8061 - val_accuracy: 0.0000e+00 - val_loss: 488.4121\n",
      "Epoch 10/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2049 - loss: 22.9701 - val_accuracy: 0.0000e+00 - val_loss: 534.4196\n",
      "Epoch 11/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2658 - loss: 14.0590 - val_accuracy: 0.0000e+00 - val_loss: 458.6312\n",
      "Epoch 12/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2626 - loss: 25.3530 - val_accuracy: 0.0000e+00 - val_loss: 557.4717\n",
      "Epoch 13/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2503 - loss: 114.2428 - val_accuracy: 0.0000e+00 - val_loss: 610.0509\n",
      "Epoch 14/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4522 - loss: 16.5935 - val_accuracy: 0.0000e+00 - val_loss: 619.7218\n",
      "Epoch 15/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1893 - loss: 6.7822 - val_accuracy: 0.0000e+00 - val_loss: 571.8927\n",
      "Epoch 16/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2388 - loss: 18.8107 - val_accuracy: 0.0000e+00 - val_loss: 482.7654\n",
      "Epoch 17/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2327 - loss: 48.3682 - val_accuracy: 0.0000e+00 - val_loss: 704.8452\n",
      "Epoch 18/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2282 - loss: 25.3955 - val_accuracy: 0.0000e+00 - val_loss: 647.6397\n",
      "Epoch 19/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2113 - loss: 18.3782 - val_accuracy: 0.0000e+00 - val_loss: 621.6201\n",
      "Epoch 20/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2812 - loss: 9.3015 - val_accuracy: 0.0000e+00 - val_loss: 566.9677\n",
      "Epoch 21/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3395 - loss: 9.0415 - val_accuracy: 0.0000e+00 - val_loss: 702.9077\n",
      "Epoch 22/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3254 - loss: 34.9455 - val_accuracy: 0.0000e+00 - val_loss: 666.5380\n",
      "Epoch 23/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2802 - loss: 10.3063 - val_accuracy: 0.0000e+00 - val_loss: 695.8618\n",
      "Epoch 24/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3077 - loss: 4.1191 - val_accuracy: 0.0000e+00 - val_loss: 739.0182\n",
      "Epoch 25/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3958 - loss: 1.8417 - val_accuracy: 0.0000e+00 - val_loss: 682.0088\n",
      "Epoch 26/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3043 - loss: 1.4268 - val_accuracy: 0.0000e+00 - val_loss: 682.0931\n",
      "Epoch 27/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2804 - loss: 1.4799 - val_accuracy: 0.0000e+00 - val_loss: 682.0942\n",
      "Epoch 28/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3381 - loss: 1.3270 - val_accuracy: 0.0000e+00 - val_loss: 682.0942\n",
      "Epoch 29/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4027 - loss: 1.2911 - val_accuracy: 0.0000e+00 - val_loss: 682.0939\n",
      "Epoch 30/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2517 - loss: 1.3696 - val_accuracy: 0.0000e+00 - val_loss: 682.0922\n",
      "Epoch 31/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3621 - loss: 1.2447 - val_accuracy: 0.0000e+00 - val_loss: 682.0928\n",
      "Epoch 32/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3052 - loss: 1.3077 - val_accuracy: 0.0000e+00 - val_loss: 682.0917\n",
      "Epoch 33/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4737 - loss: 1.3596 - val_accuracy: 0.0000e+00 - val_loss: 682.0927\n",
      "Epoch 34/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3815 - loss: 1.3569 - val_accuracy: 0.0000e+00 - val_loss: 682.0917\n",
      "Epoch 35/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2639 - loss: 1.3733 - val_accuracy: 0.0000e+00 - val_loss: 682.0902\n",
      "Epoch 36/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3201 - loss: 1.3356 - val_accuracy: 0.0000e+00 - val_loss: 682.0909\n",
      "Epoch 37/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3480 - loss: 1.4008 - val_accuracy: 0.0000e+00 - val_loss: 682.0906\n",
      "Epoch 38/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4127 - loss: 1.2248 - val_accuracy: 0.0000e+00 - val_loss: 682.0901\n",
      "Epoch 39/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3714 - loss: 1.3376 - val_accuracy: 0.0000e+00 - val_loss: 682.0897\n",
      "Epoch 40/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2219 - loss: 1.4290 - val_accuracy: 0.0000e+00 - val_loss: 682.0882\n",
      "Epoch 41/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2780 - loss: 1.3952 - val_accuracy: 0.0000e+00 - val_loss: 682.0889\n",
      "Epoch 42/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2669 - loss: 1.4022 - val_accuracy: 0.0000e+00 - val_loss: 682.0883\n",
      "Epoch 43/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3763 - loss: 1.2878 - val_accuracy: 0.0000e+00 - val_loss: 682.0882\n",
      "Epoch 44/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4711 - loss: 1.1287 - val_accuracy: 0.0000e+00 - val_loss: 682.0878\n",
      "Epoch 45/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3302 - loss: 1.3685 - val_accuracy: 0.0000e+00 - val_loss: 682.0870\n",
      "Epoch 46/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3039 - loss: 1.3546 - val_accuracy: 0.0000e+00 - val_loss: 682.0869\n",
      "Epoch 47/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3340 - loss: 1.3989 - val_accuracy: 0.0000e+00 - val_loss: 682.0870\n",
      "Epoch 48/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3275 - loss: 1.4703 - val_accuracy: 0.0000e+00 - val_loss: 682.0870\n",
      "Epoch 49/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3060 - loss: 1.2729 - val_accuracy: 0.0000e+00 - val_loss: 682.0850\n",
      "Epoch 50/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2954 - loss: 1.2600 - val_accuracy: 0.0000e+00 - val_loss: 682.0850\n",
      "Epoch 51/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4149 - loss: 1.3552 - val_accuracy: 0.0000e+00 - val_loss: 682.0856\n",
      "Epoch 52/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4520 - loss: 1.2757 - val_accuracy: 0.0000e+00 - val_loss: 682.0864\n",
      "Epoch 53/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2912 - loss: 1.4312 - val_accuracy: 0.0000e+00 - val_loss: 682.0851\n",
      "Epoch 54/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3626 - loss: 1.2598 - val_accuracy: 0.0000e+00 - val_loss: 682.0841\n",
      "Epoch 55/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3755 - loss: 1.3913 - val_accuracy: 0.0000e+00 - val_loss: 682.0858\n",
      "Epoch 56/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2871 - loss: 1.3812 - val_accuracy: 0.0000e+00 - val_loss: 682.0835\n",
      "Epoch 57/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4689 - loss: 1.3294 - val_accuracy: 0.0000e+00 - val_loss: 682.0847\n",
      "Epoch 58/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3164 - loss: 1.3831 - val_accuracy: 0.0000e+00 - val_loss: 682.0834\n",
      "Epoch 59/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4011 - loss: 1.3284 - val_accuracy: 0.0000e+00 - val_loss: 682.0827\n",
      "Epoch 60/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3916 - loss: 1.3084 - val_accuracy: 0.0000e+00 - val_loss: 682.0841\n",
      "Epoch 61/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4737 - loss: 1.3278 - val_accuracy: 0.0000e+00 - val_loss: 682.0836\n",
      "Epoch 62/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4042 - loss: 1.2788 - val_accuracy: 0.0000e+00 - val_loss: 682.0822\n",
      "Epoch 63/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4083 - loss: 1.2819 - val_accuracy: 0.0000e+00 - val_loss: 682.0818\n",
      "Epoch 64/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4047 - loss: 1.2960 - val_accuracy: 0.0000e+00 - val_loss: 682.0821\n",
      "Epoch 65/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3130 - loss: 1.4206 - val_accuracy: 0.0000e+00 - val_loss: 682.0814\n",
      "Epoch 66/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3910 - loss: 1.2547 - val_accuracy: 0.0000e+00 - val_loss: 682.0814\n",
      "Epoch 67/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4339 - loss: 1.2145 - val_accuracy: 0.0000e+00 - val_loss: 682.0807\n",
      "Epoch 68/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4156 - loss: 1.2282 - val_accuracy: 0.0000e+00 - val_loss: 682.0812\n",
      "Epoch 69/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3515 - loss: 1.3901 - val_accuracy: 0.0000e+00 - val_loss: 682.0804\n",
      "Epoch 70/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4087 - loss: 1.2716 - val_accuracy: 0.0000e+00 - val_loss: 682.0797\n",
      "Epoch 71/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2664 - loss: 1.4377 - val_accuracy: 0.0000e+00 - val_loss: 682.0797\n",
      "Epoch 72/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3957 - loss: 1.1807 - val_accuracy: 0.0000e+00 - val_loss: 682.0802\n",
      "Epoch 73/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4044 - loss: 1.2345 - val_accuracy: 0.0000e+00 - val_loss: 682.0803\n",
      "Epoch 74/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3420 - loss: 1.3456 - val_accuracy: 0.0000e+00 - val_loss: 682.0797\n",
      "Epoch 75/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4173 - loss: 1.3068 - val_accuracy: 0.0000e+00 - val_loss: 682.0797\n",
      "Epoch 76/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2457 - loss: 1.3781 - val_accuracy: 0.0000e+00 - val_loss: 682.0776\n",
      "Epoch 77/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3720 - loss: 1.3663 - val_accuracy: 0.0000e+00 - val_loss: 682.0780\n",
      "Epoch 78/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4348 - loss: 1.3269 - val_accuracy: 0.0000e+00 - val_loss: 682.0784\n",
      "Epoch 79/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1789 - loss: 1.5285 - val_accuracy: 0.0000e+00 - val_loss: 682.0778\n",
      "Epoch 80/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2628 - loss: 1.4533 - val_accuracy: 0.0000e+00 - val_loss: 682.0779\n",
      "Epoch 81/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3640 - loss: 1.3538 - val_accuracy: 0.0000e+00 - val_loss: 682.0780\n",
      "Epoch 82/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3493 - loss: 1.3546 - val_accuracy: 0.0000e+00 - val_loss: 682.0781\n",
      "Epoch 83/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5471 - loss: 1.3178 - val_accuracy: 0.0000e+00 - val_loss: 682.0782\n",
      "Epoch 84/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4517 - loss: 1.3028 - val_accuracy: 0.0000e+00 - val_loss: 682.0776\n",
      "Epoch 85/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2940 - loss: 1.4084 - val_accuracy: 0.0000e+00 - val_loss: 682.0768\n",
      "Epoch 86/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3486 - loss: 1.3262 - val_accuracy: 0.0000e+00 - val_loss: 682.0775\n",
      "Epoch 87/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4278 - loss: 1.3257 - val_accuracy: 0.0000e+00 - val_loss: 682.0772\n",
      "Epoch 88/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3301 - loss: 1.3540 - val_accuracy: 0.0000e+00 - val_loss: 682.0758\n",
      "Epoch 89/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2922 - loss: 1.4028 - val_accuracy: 0.0000e+00 - val_loss: 682.0760\n",
      "Epoch 90/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3318 - loss: 1.4271 - val_accuracy: 0.0000e+00 - val_loss: 682.0765\n",
      "Epoch 91/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3559 - loss: 1.2616 - val_accuracy: 0.0000e+00 - val_loss: 682.0761\n",
      "Epoch 92/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4171 - loss: 1.2884 - val_accuracy: 0.0000e+00 - val_loss: 682.0761\n",
      "Epoch 93/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2592 - loss: 1.4367 - val_accuracy: 0.0000e+00 - val_loss: 682.0758\n",
      "Epoch 94/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3917 - loss: 1.3712 - val_accuracy: 0.0000e+00 - val_loss: 682.0762\n",
      "Epoch 95/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3462 - loss: 1.3133 - val_accuracy: 0.0000e+00 - val_loss: 682.0760\n",
      "Epoch 96/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3057 - loss: 1.3717 - val_accuracy: 0.0000e+00 - val_loss: 682.0745\n",
      "Epoch 97/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4257 - loss: 1.3830 - val_accuracy: 0.0000e+00 - val_loss: 682.0753\n",
      "Epoch 98/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3292 - loss: 1.2943 - val_accuracy: 0.0000e+00 - val_loss: 682.0746\n",
      "Epoch 99/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2987 - loss: 1.4167 - val_accuracy: 0.0000e+00 - val_loss: 682.0753\n",
      "Epoch 100/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3984 - loss: 1.3342 - val_accuracy: 0.0000e+00 - val_loss: 682.0751\n",
      "Epoch 101/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4360 - loss: 1.2742 - val_accuracy: 0.0000e+00 - val_loss: 682.0750\n",
      "Epoch 102/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3699 - loss: 1.3231 - val_accuracy: 0.0000e+00 - val_loss: 682.0739\n",
      "Epoch 103/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4538 - loss: 1.2658 - val_accuracy: 0.0000e+00 - val_loss: 682.0754\n",
      "Epoch 104/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3026 - loss: 1.3838 - val_accuracy: 0.0000e+00 - val_loss: 682.0739\n",
      "Epoch 105/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4514 - loss: 1.2308 - val_accuracy: 0.0000e+00 - val_loss: 682.0743\n",
      "Epoch 106/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4577 - loss: 1.3776 - val_accuracy: 0.0000e+00 - val_loss: 682.0748\n",
      "Epoch 107/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3448 - loss: 1.2904 - val_accuracy: 0.0000e+00 - val_loss: 682.0740\n",
      "Epoch 108/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3478 - loss: 1.3384 - val_accuracy: 0.0000e+00 - val_loss: 682.0732\n",
      "Epoch 109/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3652 - loss: 1.3821 - val_accuracy: 0.0000e+00 - val_loss: 682.0739\n",
      "Epoch 110/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3055 - loss: 1.3276 - val_accuracy: 0.0000e+00 - val_loss: 682.0729\n",
      "Epoch 111/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2288 - loss: 1.4303 - val_accuracy: 0.0000e+00 - val_loss: 682.0730\n",
      "Epoch 112/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3528 - loss: 1.3175 - val_accuracy: 0.0000e+00 - val_loss: 682.0715\n",
      "Epoch 113/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3004 - loss: 1.2969 - val_accuracy: 0.0000e+00 - val_loss: 682.0722\n",
      "Epoch 114/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2921 - loss: 1.4790 - val_accuracy: 0.0000e+00 - val_loss: 682.0733\n",
      "Epoch 115/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3576 - loss: 1.3705 - val_accuracy: 0.0000e+00 - val_loss: 682.0735\n",
      "Epoch 116/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3807 - loss: 1.2798 - val_accuracy: 0.0000e+00 - val_loss: 682.0730\n",
      "Epoch 117/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2849 - loss: 1.3824 - val_accuracy: 0.0000e+00 - val_loss: 682.0721\n",
      "Epoch 118/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4331 - loss: 1.2955 - val_accuracy: 0.0000e+00 - val_loss: 682.0738\n",
      "Epoch 119/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2792 - loss: 1.3274 - val_accuracy: 0.0000e+00 - val_loss: 682.0719\n",
      "Epoch 120/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4825 - loss: 1.1229 - val_accuracy: 0.0000e+00 - val_loss: 682.0733\n",
      "Epoch 121/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3915 - loss: 1.2730 - val_accuracy: 0.0000e+00 - val_loss: 682.0725\n",
      "Epoch 122/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2725 - loss: 1.4422 - val_accuracy: 0.0000e+00 - val_loss: 682.0721\n",
      "Epoch 123/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3981 - loss: 1.2352 - val_accuracy: 0.0000e+00 - val_loss: 682.0715\n",
      "Epoch 124/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3013 - loss: 1.4482 - val_accuracy: 0.0000e+00 - val_loss: 682.0723\n",
      "Epoch 125/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3701 - loss: 1.2224 - val_accuracy: 0.0000e+00 - val_loss: 682.0710\n",
      "Epoch 126/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3344 - loss: 1.3987 - val_accuracy: 0.0000e+00 - val_loss: 682.0719\n",
      "Epoch 127/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2344 - loss: 1.4231 - val_accuracy: 0.0000e+00 - val_loss: 682.0712\n",
      "Epoch 128/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4003 - loss: 1.2236 - val_accuracy: 0.0000e+00 - val_loss: 682.0720\n",
      "Epoch 129/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4051 - loss: 1.3211 - val_accuracy: 0.0000e+00 - val_loss: 682.0717\n",
      "Epoch 130/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5249 - loss: 1.1013 - val_accuracy: 0.0000e+00 - val_loss: 682.0723\n",
      "Epoch 131/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4325 - loss: 1.1357 - val_accuracy: 0.0000e+00 - val_loss: 682.0719\n",
      "Epoch 132/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3773 - loss: 1.3580 - val_accuracy: 0.0000e+00 - val_loss: 682.0712\n",
      "Epoch 133/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3940 - loss: 1.4137 - val_accuracy: 0.0000e+00 - val_loss: 682.0714\n",
      "Epoch 134/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4423 - loss: 1.2038 - val_accuracy: 0.0000e+00 - val_loss: 682.0715\n",
      "Epoch 135/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2931 - loss: 1.4156 - val_accuracy: 0.0000e+00 - val_loss: 682.0712\n",
      "Epoch 136/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3996 - loss: 1.2273 - val_accuracy: 0.0000e+00 - val_loss: 682.0709\n",
      "Epoch 137/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4934 - loss: 1.0942 - val_accuracy: 0.0000e+00 - val_loss: 682.0709\n",
      "Epoch 138/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2617 - loss: 1.3952 - val_accuracy: 0.0000e+00 - val_loss: 682.0702\n",
      "Epoch 139/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4451 - loss: 1.3092 - val_accuracy: 0.0000e+00 - val_loss: 682.0709\n",
      "Epoch 140/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4351 - loss: 1.4195 - val_accuracy: 0.0000e+00 - val_loss: 682.0714\n",
      "Epoch 141/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3025 - loss: 1.4530 - val_accuracy: 0.0000e+00 - val_loss: 682.0699\n",
      "Epoch 142/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3226 - loss: 1.4591 - val_accuracy: 0.0000e+00 - val_loss: 682.0709\n",
      "Epoch 143/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3788 - loss: 1.3933 - val_accuracy: 0.0000e+00 - val_loss: 682.0710\n",
      "Epoch 144/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3551 - loss: 1.3146 - val_accuracy: 0.0000e+00 - val_loss: 682.0695\n",
      "Epoch 145/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3445 - loss: 1.4001 - val_accuracy: 0.0000e+00 - val_loss: 682.0714\n",
      "Epoch 146/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4696 - loss: 1.2091 - val_accuracy: 0.0000e+00 - val_loss: 682.0701\n",
      "Epoch 147/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4641 - loss: 1.2188 - val_accuracy: 0.0000e+00 - val_loss: 682.0714\n",
      "Epoch 148/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4276 - loss: 1.3015 - val_accuracy: 0.0000e+00 - val_loss: 682.0697\n",
      "Epoch 149/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4319 - loss: 1.3597 - val_accuracy: 0.0000e+00 - val_loss: 682.0710\n",
      "Epoch 150/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3106 - loss: 1.4221 - val_accuracy: 0.0000e+00 - val_loss: 682.0699\n",
      "Epoch 151/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3434 - loss: 1.3051 - val_accuracy: 0.0000e+00 - val_loss: 682.0695\n",
      "Epoch 152/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3104 - loss: 1.4751 - val_accuracy: 0.0000e+00 - val_loss: 682.0706\n",
      "Epoch 153/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4264 - loss: 1.2777 - val_accuracy: 0.0000e+00 - val_loss: 682.0701\n",
      "Epoch 154/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3987 - loss: 1.1568 - val_accuracy: 0.0000e+00 - val_loss: 682.0693\n",
      "Epoch 155/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2974 - loss: 1.4447 - val_accuracy: 0.0000e+00 - val_loss: 682.0692\n",
      "Epoch 156/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2527 - loss: 1.4525 - val_accuracy: 0.0000e+00 - val_loss: 682.0696\n",
      "Epoch 157/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4580 - loss: 1.2915 - val_accuracy: 0.0000e+00 - val_loss: 682.0705\n",
      "Epoch 158/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3972 - loss: 1.2988 - val_accuracy: 0.0000e+00 - val_loss: 682.0696\n",
      "Epoch 159/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4241 - loss: 1.2612 - val_accuracy: 0.0000e+00 - val_loss: 682.0697\n",
      "Epoch 160/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3516 - loss: 1.3759 - val_accuracy: 0.0000e+00 - val_loss: 682.0699\n",
      "Epoch 161/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4394 - loss: 1.1580 - val_accuracy: 0.0000e+00 - val_loss: 682.0697\n",
      "Epoch 162/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3911 - loss: 1.3368 - val_accuracy: 0.0000e+00 - val_loss: 682.0692\n",
      "Epoch 163/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3717 - loss: 1.2991 - val_accuracy: 0.0000e+00 - val_loss: 682.0690\n",
      "Epoch 164/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4431 - loss: 1.1530 - val_accuracy: 0.0000e+00 - val_loss: 682.0700\n",
      "Epoch 165/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3117 - loss: 1.3026 - val_accuracy: 0.0000e+00 - val_loss: 682.0684\n",
      "Epoch 166/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4348 - loss: 1.1915 - val_accuracy: 0.0000e+00 - val_loss: 682.0686\n",
      "Epoch 167/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3007 - loss: 1.3956 - val_accuracy: 0.0000e+00 - val_loss: 682.0689\n",
      "Epoch 168/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4101 - loss: 1.4068 - val_accuracy: 0.0000e+00 - val_loss: 682.0703\n",
      "Epoch 169/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3483 - loss: 1.3061 - val_accuracy: 0.0000e+00 - val_loss: 682.0678\n",
      "Epoch 170/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3288 - loss: 1.4398 - val_accuracy: 0.0000e+00 - val_loss: 682.0689\n",
      "Epoch 171/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4136 - loss: 1.2666 - val_accuracy: 0.0000e+00 - val_loss: 682.0698\n",
      "Epoch 172/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4808 - loss: 1.3080 - val_accuracy: 0.0000e+00 - val_loss: 682.0692\n",
      "Epoch 173/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3824 - loss: 1.3897 - val_accuracy: 0.0000e+00 - val_loss: 682.0695\n",
      "Epoch 174/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2863 - loss: 1.3689 - val_accuracy: 0.0000e+00 - val_loss: 682.0676\n",
      "Epoch 175/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2362 - loss: 1.4274 - val_accuracy: 0.0000e+00 - val_loss: 682.0681\n",
      "Epoch 176/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3721 - loss: 1.2889 - val_accuracy: 0.0000e+00 - val_loss: 682.0684\n",
      "Epoch 177/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3573 - loss: 1.3777 - val_accuracy: 0.0000e+00 - val_loss: 682.0697\n",
      "Epoch 178/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3952 - loss: 1.1787 - val_accuracy: 0.0000e+00 - val_loss: 682.0692\n",
      "Epoch 179/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3849 - loss: 1.4293 - val_accuracy: 0.0000e+00 - val_loss: 682.0695\n",
      "Epoch 180/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4108 - loss: 1.2907 - val_accuracy: 0.0000e+00 - val_loss: 682.0685\n",
      "Epoch 181/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3341 - loss: 1.2716 - val_accuracy: 0.0000e+00 - val_loss: 682.0685\n",
      "Epoch 182/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4081 - loss: 1.3111 - val_accuracy: 0.0000e+00 - val_loss: 682.0682\n",
      "Epoch 183/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4199 - loss: 1.3962 - val_accuracy: 0.0000e+00 - val_loss: 682.0685\n",
      "Epoch 184/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2708 - loss: 1.3857 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 185/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3381 - loss: 1.2529 - val_accuracy: 0.0000e+00 - val_loss: 682.0686\n",
      "Epoch 186/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4675 - loss: 1.2790 - val_accuracy: 0.0000e+00 - val_loss: 682.0688\n",
      "Epoch 187/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2318 - loss: 1.4335 - val_accuracy: 0.0000e+00 - val_loss: 682.0680\n",
      "Epoch 188/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4077 - loss: 1.2109 - val_accuracy: 0.0000e+00 - val_loss: 682.0693\n",
      "Epoch 189/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4489 - loss: 1.2601 - val_accuracy: 0.0000e+00 - val_loss: 682.0684\n",
      "Epoch 190/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3066 - loss: 1.4033 - val_accuracy: 0.0000e+00 - val_loss: 682.0687\n",
      "Epoch 191/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2309 - loss: 1.3587 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 192/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3753 - loss: 1.3038 - val_accuracy: 0.0000e+00 - val_loss: 682.0692\n",
      "Epoch 193/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4184 - loss: 1.2647 - val_accuracy: 0.0000e+00 - val_loss: 682.0688\n",
      "Epoch 194/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4294 - loss: 1.2785 - val_accuracy: 0.0000e+00 - val_loss: 682.0679\n",
      "Epoch 195/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4060 - loss: 1.3522 - val_accuracy: 0.0000e+00 - val_loss: 682.0682\n",
      "Epoch 196/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4886 - loss: 1.3015 - val_accuracy: 0.0000e+00 - val_loss: 682.0683\n",
      "Epoch 197/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2449 - loss: 1.3901 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 198/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4057 - loss: 1.2245 - val_accuracy: 0.0000e+00 - val_loss: 682.0675\n",
      "Epoch 199/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3400 - loss: 1.2765 - val_accuracy: 0.0000e+00 - val_loss: 682.0677\n",
      "Epoch 200/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4695 - loss: 1.2205 - val_accuracy: 0.0000e+00 - val_loss: 682.0676\n",
      "Epoch 201/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5089 - loss: 1.2275 - val_accuracy: 0.0000e+00 - val_loss: 682.0688\n",
      "Epoch 202/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3524 - loss: 1.4365 - val_accuracy: 0.0000e+00 - val_loss: 682.0682\n",
      "Epoch 203/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4148 - loss: 1.4057 - val_accuracy: 0.0000e+00 - val_loss: 682.0680\n",
      "Epoch 204/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3165 - loss: 1.4698 - val_accuracy: 0.0000e+00 - val_loss: 682.0679\n",
      "Epoch 205/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3284 - loss: 1.3427 - val_accuracy: 0.0000e+00 - val_loss: 682.0685\n",
      "Epoch 206/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2484 - loss: 1.3990 - val_accuracy: 0.0000e+00 - val_loss: 682.0671\n",
      "Epoch 207/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1983 - loss: 1.5594 - val_accuracy: 0.0000e+00 - val_loss: 682.0676\n",
      "Epoch 208/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3106 - loss: 1.3688 - val_accuracy: 0.0000e+00 - val_loss: 682.0680\n",
      "Epoch 209/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2716 - loss: 1.4041 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 210/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4076 - loss: 1.3272 - val_accuracy: 0.0000e+00 - val_loss: 682.0674\n",
      "Epoch 211/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5040 - loss: 1.1709 - val_accuracy: 0.0000e+00 - val_loss: 682.0679\n",
      "Epoch 212/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2915 - loss: 1.4033 - val_accuracy: 0.0000e+00 - val_loss: 682.0677\n",
      "Epoch 213/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2792 - loss: 1.4258 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 214/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3049 - loss: 1.3116 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 215/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3465 - loss: 1.3847 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 216/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4551 - loss: 1.3336 - val_accuracy: 0.0000e+00 - val_loss: 682.0685\n",
      "Epoch 217/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4979 - loss: 1.1435 - val_accuracy: 0.0000e+00 - val_loss: 682.0682\n",
      "Epoch 218/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3836 - loss: 1.3187 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 219/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3099 - loss: 1.3568 - val_accuracy: 0.0000e+00 - val_loss: 682.0677\n",
      "Epoch 220/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3418 - loss: 1.3522 - val_accuracy: 0.0000e+00 - val_loss: 682.0665\n",
      "Epoch 221/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4376 - loss: 1.1441 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 222/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3273 - loss: 1.3892 - val_accuracy: 0.0000e+00 - val_loss: 682.0682\n",
      "Epoch 223/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3003 - loss: 1.3426 - val_accuracy: 0.0000e+00 - val_loss: 682.0679\n",
      "Epoch 224/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4578 - loss: 1.1274 - val_accuracy: 0.0000e+00 - val_loss: 682.0675\n",
      "Epoch 225/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3255 - loss: 1.4855 - val_accuracy: 0.0000e+00 - val_loss: 682.0675\n",
      "Epoch 226/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3438 - loss: 1.3294 - val_accuracy: 0.0000e+00 - val_loss: 682.0666\n",
      "Epoch 227/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2223 - loss: 1.3762 - val_accuracy: 0.0000e+00 - val_loss: 682.0660\n",
      "Epoch 228/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4783 - loss: 1.1852 - val_accuracy: 0.0000e+00 - val_loss: 682.0675\n",
      "Epoch 229/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5553 - loss: 1.3426 - val_accuracy: 0.0000e+00 - val_loss: 682.0684\n",
      "Epoch 230/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2394 - loss: 1.4301 - val_accuracy: 0.0000e+00 - val_loss: 682.0675\n",
      "Epoch 231/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3364 - loss: 1.3471 - val_accuracy: 0.0000e+00 - val_loss: 682.0677\n",
      "Epoch 232/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3861 - loss: 1.1940 - val_accuracy: 0.0000e+00 - val_loss: 682.0674\n",
      "Epoch 233/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3609 - loss: 1.3497 - val_accuracy: 0.0000e+00 - val_loss: 682.0684\n",
      "Epoch 234/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3693 - loss: 1.3660 - val_accuracy: 0.0000e+00 - val_loss: 682.0675\n",
      "Epoch 235/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2714 - loss: 1.4648 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 236/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2965 - loss: 1.3683 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 237/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5610 - loss: 1.1228 - val_accuracy: 0.0000e+00 - val_loss: 682.0680\n",
      "Epoch 238/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4632 - loss: 1.1326 - val_accuracy: 0.0000e+00 - val_loss: 682.0671\n",
      "Epoch 239/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4171 - loss: 1.2483 - val_accuracy: 0.0000e+00 - val_loss: 682.0677\n",
      "Epoch 240/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3674 - loss: 1.2823 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 241/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3412 - loss: 1.3703 - val_accuracy: 0.0000e+00 - val_loss: 682.0678\n",
      "Epoch 242/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4172 - loss: 1.2546 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 243/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3187 - loss: 1.3377 - val_accuracy: 0.0000e+00 - val_loss: 682.0677\n",
      "Epoch 244/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4616 - loss: 1.3507 - val_accuracy: 0.0000e+00 - val_loss: 682.0679\n",
      "Epoch 245/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4110 - loss: 1.2943 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 246/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3974 - loss: 1.2939 - val_accuracy: 0.0000e+00 - val_loss: 682.0671\n",
      "Epoch 247/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3166 - loss: 1.4628 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 248/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3410 - loss: 1.3926 - val_accuracy: 0.0000e+00 - val_loss: 682.0665\n",
      "Epoch 249/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4038 - loss: 1.2823 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 250/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4716 - loss: 1.2831 - val_accuracy: 0.0000e+00 - val_loss: 682.0675\n",
      "Epoch 251/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3713 - loss: 1.3240 - val_accuracy: 0.0000e+00 - val_loss: 682.0675\n",
      "Epoch 252/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3769 - loss: 1.4351 - val_accuracy: 0.0000e+00 - val_loss: 682.0676\n",
      "Epoch 253/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4150 - loss: 1.3318 - val_accuracy: 0.0000e+00 - val_loss: 682.0662\n",
      "Epoch 254/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4070 - loss: 1.1354 - val_accuracy: 0.0000e+00 - val_loss: 682.0663\n",
      "Epoch 255/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2594 - loss: 1.4316 - val_accuracy: 0.0000e+00 - val_loss: 682.0667\n",
      "Epoch 256/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3288 - loss: 1.2711 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 257/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4939 - loss: 1.2592 - val_accuracy: 0.0000e+00 - val_loss: 682.0671\n",
      "Epoch 258/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3107 - loss: 1.2732 - val_accuracy: 0.0000e+00 - val_loss: 682.0659\n",
      "Epoch 259/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3377 - loss: 1.3476 - val_accuracy: 0.0000e+00 - val_loss: 682.0667\n",
      "Epoch 260/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5419 - loss: 1.1515 - val_accuracy: 0.0000e+00 - val_loss: 682.0680\n",
      "Epoch 261/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4657 - loss: 1.1925 - val_accuracy: 0.0000e+00 - val_loss: 682.0677\n",
      "Epoch 262/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4322 - loss: 1.3798 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 263/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3634 - loss: 1.2330 - val_accuracy: 0.0000e+00 - val_loss: 682.0669\n",
      "Epoch 264/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3786 - loss: 1.2224 - val_accuracy: 0.0000e+00 - val_loss: 682.0671\n",
      "Epoch 265/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3349 - loss: 1.3480 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 266/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3419 - loss: 1.3118 - val_accuracy: 0.0000e+00 - val_loss: 682.0664\n",
      "Epoch 267/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3899 - loss: 1.3571 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 268/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3973 - loss: 1.2401 - val_accuracy: 0.0000e+00 - val_loss: 682.0671\n",
      "Epoch 269/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4655 - loss: 1.1366 - val_accuracy: 0.0000e+00 - val_loss: 682.0669\n",
      "Epoch 270/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2924 - loss: 1.3487 - val_accuracy: 0.0000e+00 - val_loss: 682.0663\n",
      "Epoch 271/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2904 - loss: 1.3107 - val_accuracy: 0.0000e+00 - val_loss: 682.0658\n",
      "Epoch 272/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4078 - loss: 1.1187 - val_accuracy: 0.0000e+00 - val_loss: 682.0663\n",
      "Epoch 273/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2873 - loss: 1.4579 - val_accuracy: 0.0000e+00 - val_loss: 682.0663\n",
      "Epoch 274/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3859 - loss: 1.2679 - val_accuracy: 0.0000e+00 - val_loss: 682.0661\n",
      "Epoch 275/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3596 - loss: 1.2078 - val_accuracy: 0.0000e+00 - val_loss: 682.0654\n",
      "Epoch 276/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4168 - loss: 1.2826 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 277/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4361 - loss: 1.2180 - val_accuracy: 0.0000e+00 - val_loss: 682.0666\n",
      "Epoch 278/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3993 - loss: 1.1518 - val_accuracy: 0.0000e+00 - val_loss: 682.0660\n",
      "Epoch 279/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4099 - loss: 1.2810 - val_accuracy: 0.0000e+00 - val_loss: 682.0657\n",
      "Epoch 280/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3652 - loss: 1.3612 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 281/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3988 - loss: 1.3678 - val_accuracy: 0.0000e+00 - val_loss: 682.0679\n",
      "Epoch 282/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2813 - loss: 1.3980 - val_accuracy: 0.0000e+00 - val_loss: 682.0671\n",
      "Epoch 283/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4383 - loss: 1.3441 - val_accuracy: 0.0000e+00 - val_loss: 682.0663\n",
      "Epoch 284/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4215 - loss: 1.4073 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 285/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3725 - loss: 1.2820 - val_accuracy: 0.0000e+00 - val_loss: 682.0669\n",
      "Epoch 286/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5001 - loss: 1.2070 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 287/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4274 - loss: 1.3207 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 288/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5143 - loss: 1.2429 - val_accuracy: 0.0000e+00 - val_loss: 682.0682\n",
      "Epoch 289/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3006 - loss: 1.4167 - val_accuracy: 0.0000e+00 - val_loss: 682.0667\n",
      "Epoch 290/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4669 - loss: 1.3098 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 291/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3739 - loss: 1.3090 - val_accuracy: 0.0000e+00 - val_loss: 682.0676\n",
      "Epoch 292/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3338 - loss: 1.3220 - val_accuracy: 0.0000e+00 - val_loss: 682.0656\n",
      "Epoch 293/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4146 - loss: 1.2740 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 294/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2597 - loss: 1.3496 - val_accuracy: 0.0000e+00 - val_loss: 682.0661\n",
      "Epoch 295/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2998 - loss: 1.4154 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 296/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2939 - loss: 1.3859 - val_accuracy: 0.0000e+00 - val_loss: 682.0662\n",
      "Epoch 297/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4167 - loss: 1.2438 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 298/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2581 - loss: 1.4128 - val_accuracy: 0.0000e+00 - val_loss: 682.0656\n",
      "Epoch 299/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3132 - loss: 1.3386 - val_accuracy: 0.0000e+00 - val_loss: 682.0658\n",
      "Epoch 300/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5340 - loss: 1.2971 - val_accuracy: 0.0000e+00 - val_loss: 682.0675\n",
      "Epoch 301/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3012 - loss: 1.4063 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 302/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5127 - loss: 1.2578 - val_accuracy: 0.0000e+00 - val_loss: 682.0671\n",
      "Epoch 303/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4770 - loss: 1.0958 - val_accuracy: 0.0000e+00 - val_loss: 682.0672\n",
      "Epoch 304/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4260 - loss: 1.2006 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 305/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4903 - loss: 1.1308 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 306/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3782 - loss: 1.3303 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 307/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3445 - loss: 1.3752 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 308/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3998 - loss: 1.3322 - val_accuracy: 0.0000e+00 - val_loss: 682.0664\n",
      "Epoch 309/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2815 - loss: 1.3861 - val_accuracy: 0.0000e+00 - val_loss: 682.0665\n",
      "Epoch 310/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4061 - loss: 1.2918 - val_accuracy: 0.0000e+00 - val_loss: 682.0659\n",
      "Epoch 311/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4781 - loss: 1.1819 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 312/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3945 - loss: 1.2903 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 313/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3608 - loss: 1.3288 - val_accuracy: 0.0000e+00 - val_loss: 682.0677\n",
      "Epoch 314/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3894 - loss: 1.1518 - val_accuracy: 0.0000e+00 - val_loss: 682.0657\n",
      "Epoch 315/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3214 - loss: 1.4953 - val_accuracy: 0.0000e+00 - val_loss: 682.0667\n",
      "Epoch 316/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3359 - loss: 1.3860 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 317/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3138 - loss: 1.3016 - val_accuracy: 0.0000e+00 - val_loss: 682.0658\n",
      "Epoch 318/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3438 - loss: 1.4208 - val_accuracy: 0.0000e+00 - val_loss: 682.0674\n",
      "Epoch 319/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4192 - loss: 1.1564 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 320/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3796 - loss: 1.3528 - val_accuracy: 0.0000e+00 - val_loss: 682.0671\n",
      "Epoch 321/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4905 - loss: 1.1053 - val_accuracy: 0.0000e+00 - val_loss: 682.0665\n",
      "Epoch 322/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3444 - loss: 1.3132 - val_accuracy: 0.0000e+00 - val_loss: 682.0659\n",
      "Epoch 323/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3577 - loss: 1.3408 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 324/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4869 - loss: 1.3817 - val_accuracy: 0.0000e+00 - val_loss: 682.0665\n",
      "Epoch 325/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3977 - loss: 1.2829 - val_accuracy: 0.0000e+00 - val_loss: 682.0667\n",
      "Epoch 326/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5683 - loss: 1.1505 - val_accuracy: 0.0000e+00 - val_loss: 682.0673\n",
      "Epoch 327/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4080 - loss: 1.2331 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 328/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4353 - loss: 1.2801 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 329/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3083 - loss: 1.4048 - val_accuracy: 0.0000e+00 - val_loss: 682.0656\n",
      "Epoch 330/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3549 - loss: 1.4745 - val_accuracy: 0.0000e+00 - val_loss: 682.0667\n",
      "Epoch 331/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3579 - loss: 1.3735 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 332/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2842 - loss: 1.5301 - val_accuracy: 0.0000e+00 - val_loss: 682.0670\n",
      "Epoch 333/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3456 - loss: 1.3351 - val_accuracy: 0.0000e+00 - val_loss: 682.0665\n",
      "Epoch 334/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3913 - loss: 1.2049 - val_accuracy: 0.0000e+00 - val_loss: 682.0652\n",
      "Epoch 335/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3196 - loss: 1.4520 - val_accuracy: 0.0000e+00 - val_loss: 682.0662\n",
      "Epoch 336/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2818 - loss: 1.3702 - val_accuracy: 0.0000e+00 - val_loss: 682.0656\n",
      "Epoch 337/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3237 - loss: 1.4445 - val_accuracy: 0.0000e+00 - val_loss: 682.0665\n",
      "Epoch 338/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4305 - loss: 1.3431 - val_accuracy: 0.0000e+00 - val_loss: 682.0667\n",
      "Epoch 339/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4513 - loss: 1.2211 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 340/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4275 - loss: 1.3168 - val_accuracy: 0.0000e+00 - val_loss: 682.0658\n",
      "Epoch 341/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3969 - loss: 1.3932 - val_accuracy: 0.0000e+00 - val_loss: 682.0668\n",
      "Epoch 342/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3935 - loss: 1.3109 - val_accuracy: 0.0000e+00 - val_loss: 682.0661\n",
      "Epoch 343/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3986 - loss: 1.1409 - val_accuracy: 0.0000e+00 - val_loss: 682.0663\n",
      "Epoch 344/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5200 - loss: 1.2743 - val_accuracy: 0.0000e+00 - val_loss: 682.0660\n",
      "Epoch 345/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4013 - loss: 1.1967 - val_accuracy: 0.0000e+00 - val_loss: 682.0651\n",
      "Epoch 346/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3208 - loss: 1.3737 - val_accuracy: 0.0000e+00 - val_loss: 682.0650\n",
      "Epoch 347/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4860 - loss: 1.1843 - val_accuracy: 0.0000e+00 - val_loss: 682.0654\n",
      "Epoch 348/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4160 - loss: 1.1886 - val_accuracy: 0.0000e+00 - val_loss: 682.0657\n",
      "Epoch 349/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3678 - loss: 1.3092 - val_accuracy: 0.0000e+00 - val_loss: 682.0652\n",
      "Epoch 350/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4681 - loss: 1.2607 - val_accuracy: 0.0000e+00 - val_loss: 682.0658\n",
      "Epoch 351/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3894 - loss: 1.2855 - val_accuracy: 0.0000e+00 - val_loss: 682.0652\n",
      "Epoch 352/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4225 - loss: 1.2422 - val_accuracy: 0.0000e+00 - val_loss: 682.0651\n",
      "Epoch 353/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2915 - loss: 1.4286 - val_accuracy: 0.0000e+00 - val_loss: 682.0658\n",
      "Epoch 354/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3351 - loss: 1.2834 - val_accuracy: 0.0000e+00 - val_loss: 682.0651\n",
      "Epoch 355/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4043 - loss: 1.1408 - val_accuracy: 0.0000e+00 - val_loss: 682.0641\n",
      "Epoch 356/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3139 - loss: 1.3254 - val_accuracy: 0.0000e+00 - val_loss: 682.0645\n",
      "Epoch 357/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4182 - loss: 1.1427 - val_accuracy: 0.0000e+00 - val_loss: 682.0647\n",
      "Epoch 358/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3693 - loss: 1.3188 - val_accuracy: 0.0000e+00 - val_loss: 682.0657\n",
      "Epoch 359/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3286 - loss: 1.3740 - val_accuracy: 0.0000e+00 - val_loss: 682.0641\n",
      "Epoch 360/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2903 - loss: 1.4204 - val_accuracy: 0.0000e+00 - val_loss: 682.0646\n",
      "Epoch 361/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4807 - loss: 1.1630 - val_accuracy: 0.0000e+00 - val_loss: 682.0652\n",
      "Epoch 362/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3150 - loss: 1.4400 - val_accuracy: 0.0000e+00 - val_loss: 682.0648\n",
      "Epoch 363/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3615 - loss: 1.3128 - val_accuracy: 0.0000e+00 - val_loss: 682.0646\n",
      "Epoch 364/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3569 - loss: 1.2831 - val_accuracy: 0.0000e+00 - val_loss: 682.0635\n",
      "Epoch 365/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3838 - loss: 1.3264 - val_accuracy: 0.0000e+00 - val_loss: 682.0650\n",
      "Epoch 366/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3709 - loss: 1.2688 - val_accuracy: 0.0000e+00 - val_loss: 682.0644\n",
      "Epoch 367/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2660 - loss: 1.4807 - val_accuracy: 0.0000e+00 - val_loss: 682.0644\n",
      "Epoch 368/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2894 - loss: 1.3916 - val_accuracy: 0.0000e+00 - val_loss: 682.0630\n",
      "Epoch 369/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3943 - loss: 1.2971 - val_accuracy: 0.0000e+00 - val_loss: 682.0635\n",
      "Epoch 370/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3941 - loss: 1.2632 - val_accuracy: 0.0000e+00 - val_loss: 682.0639\n",
      "Epoch 371/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3562 - loss: 1.4930 - val_accuracy: 0.0000e+00 - val_loss: 682.0638\n",
      "Epoch 372/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3801 - loss: 1.4649 - val_accuracy: 0.0000e+00 - val_loss: 682.0642\n",
      "Epoch 373/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2811 - loss: 1.3546 - val_accuracy: 0.0000e+00 - val_loss: 682.0625\n",
      "Epoch 374/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4332 - loss: 1.3305 - val_accuracy: 0.0000e+00 - val_loss: 682.0634\n",
      "Epoch 375/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5550 - loss: 1.1953 - val_accuracy: 0.0000e+00 - val_loss: 682.0641\n",
      "Epoch 376/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3386 - loss: 1.4048 - val_accuracy: 0.0000e+00 - val_loss: 682.0631\n",
      "Epoch 377/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2494 - loss: 1.3863 - val_accuracy: 0.0000e+00 - val_loss: 682.0616\n",
      "Epoch 378/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3835 - loss: 1.3436 - val_accuracy: 0.0000e+00 - val_loss: 682.0628\n",
      "Epoch 379/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2860 - loss: 1.4242 - val_accuracy: 0.0000e+00 - val_loss: 682.0619\n",
      "Epoch 380/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4516 - loss: 1.1578 - val_accuracy: 0.0000e+00 - val_loss: 682.0613\n",
      "Epoch 381/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4083 - loss: 1.2677 - val_accuracy: 0.0000e+00 - val_loss: 682.0619\n",
      "Epoch 382/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3005 - loss: 1.2914 - val_accuracy: 0.0000e+00 - val_loss: 682.0609\n",
      "Epoch 383/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3374 - loss: 1.3937 - val_accuracy: 0.0000e+00 - val_loss: 682.0613\n",
      "Epoch 384/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3276 - loss: 1.3859 - val_accuracy: 0.0000e+00 - val_loss: 682.0610\n",
      "Epoch 385/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2868 - loss: 1.4637 - val_accuracy: 0.0000e+00 - val_loss: 682.0602\n",
      "Epoch 386/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4694 - loss: 1.2740 - val_accuracy: 0.0000e+00 - val_loss: 682.0609\n",
      "Epoch 387/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3832 - loss: 1.1517 - val_accuracy: 0.0000e+00 - val_loss: 682.0590\n",
      "Epoch 388/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3908 - loss: 1.4107 - val_accuracy: 0.0000e+00 - val_loss: 682.0605\n",
      "Epoch 389/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4101 - loss: 1.2646 - val_accuracy: 0.0000e+00 - val_loss: 682.0590\n",
      "Epoch 390/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4672 - loss: 1.3755 - val_accuracy: 0.0000e+00 - val_loss: 682.0601\n",
      "Epoch 391/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2970 - loss: 1.3167 - val_accuracy: 0.0000e+00 - val_loss: 682.0585\n",
      "Epoch 392/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5282 - loss: 1.1038 - val_accuracy: 0.0000e+00 - val_loss: 682.0593\n",
      "Epoch 393/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3063 - loss: 1.3941 - val_accuracy: 0.0000e+00 - val_loss: 682.0583\n",
      "Epoch 394/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5061 - loss: 1.1359 - val_accuracy: 0.0000e+00 - val_loss: 682.0588\n",
      "Epoch 395/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4289 - loss: 1.3762 - val_accuracy: 0.0000e+00 - val_loss: 682.0571\n",
      "Epoch 396/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3632 - loss: 1.4333 - val_accuracy: 0.0000e+00 - val_loss: 682.0570\n",
      "Epoch 397/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4177 - loss: 1.2485 - val_accuracy: 0.0000e+00 - val_loss: 682.0563\n",
      "Epoch 398/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3807 - loss: 1.2792 - val_accuracy: 0.0000e+00 - val_loss: 682.0558\n",
      "Epoch 399/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2461 - loss: 1.4611 - val_accuracy: 0.0000e+00 - val_loss: 682.0554\n",
      "Epoch 400/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5109 - loss: 1.2012 - val_accuracy: 0.0000e+00 - val_loss: 682.0568\n",
      "Epoch 401/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4515 - loss: 1.2985 - val_accuracy: 0.0000e+00 - val_loss: 682.0552\n",
      "Epoch 402/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4354 - loss: 1.1901 - val_accuracy: 0.0000e+00 - val_loss: 682.0538\n",
      "Epoch 403/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2525 - loss: 1.3834 - val_accuracy: 0.0000e+00 - val_loss: 682.0531\n",
      "Epoch 404/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5330 - loss: 1.0471 - val_accuracy: 0.0000e+00 - val_loss: 682.0536\n",
      "Epoch 405/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3284 - loss: 1.2732 - val_accuracy: 0.0000e+00 - val_loss: 682.0536\n",
      "Epoch 406/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3027 - loss: 1.3908 - val_accuracy: 0.0000e+00 - val_loss: 682.0526\n",
      "Epoch 407/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4664 - loss: 1.2014 - val_accuracy: 0.0000e+00 - val_loss: 682.0527\n",
      "Epoch 408/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2463 - loss: 1.4674 - val_accuracy: 0.0000e+00 - val_loss: 682.0511\n",
      "Epoch 409/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2258 - loss: 1.4585 - val_accuracy: 0.0000e+00 - val_loss: 682.0502\n",
      "Epoch 410/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4573 - loss: 1.2400 - val_accuracy: 0.0000e+00 - val_loss: 682.0504\n",
      "Epoch 411/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5386 - loss: 1.2231 - val_accuracy: 0.0000e+00 - val_loss: 682.0509\n",
      "Epoch 412/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2794 - loss: 1.3108 - val_accuracy: 0.0000e+00 - val_loss: 682.0483\n",
      "Epoch 413/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4457 - loss: 1.2307 - val_accuracy: 0.0000e+00 - val_loss: 682.0478\n",
      "Epoch 414/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3926 - loss: 1.3126 - val_accuracy: 0.0000e+00 - val_loss: 682.0479\n",
      "Epoch 415/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4300 - loss: 1.3225 - val_accuracy: 0.0000e+00 - val_loss: 682.0485\n",
      "Epoch 416/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3621 - loss: 1.3406 - val_accuracy: 0.0000e+00 - val_loss: 682.0470\n",
      "Epoch 417/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2675 - loss: 1.3566 - val_accuracy: 0.0000e+00 - val_loss: 682.0457\n",
      "Epoch 418/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2751 - loss: 1.4293 - val_accuracy: 0.0000e+00 - val_loss: 682.0454\n",
      "Epoch 419/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3119 - loss: 1.4703 - val_accuracy: 0.0000e+00 - val_loss: 682.0460\n",
      "Epoch 420/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2607 - loss: 1.4064 - val_accuracy: 0.0000e+00 - val_loss: 682.0440\n",
      "Epoch 421/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3236 - loss: 1.3393 - val_accuracy: 0.0000e+00 - val_loss: 682.0441\n",
      "Epoch 422/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3889 - loss: 1.3297 - val_accuracy: 0.0000e+00 - val_loss: 682.0442\n",
      "Epoch 423/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4200 - loss: 1.3235 - val_accuracy: 0.0000e+00 - val_loss: 682.0425\n",
      "Epoch 424/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4514 - loss: 1.3448 - val_accuracy: 0.0000e+00 - val_loss: 682.0421\n",
      "Epoch 425/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4182 - loss: 1.4160 - val_accuracy: 0.0000e+00 - val_loss: 682.0413\n",
      "Epoch 426/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3548 - loss: 1.4228 - val_accuracy: 0.0000e+00 - val_loss: 682.0403\n",
      "Epoch 427/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4511 - loss: 1.2304 - val_accuracy: 0.0000e+00 - val_loss: 682.0389\n",
      "Epoch 428/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2999 - loss: 1.3476 - val_accuracy: 0.0000e+00 - val_loss: 682.0377\n",
      "Epoch 429/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3161 - loss: 1.3200 - val_accuracy: 0.0000e+00 - val_loss: 682.0371\n",
      "Epoch 430/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3567 - loss: 1.2421 - val_accuracy: 0.0000e+00 - val_loss: 682.0366\n",
      "Epoch 431/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4726 - loss: 1.1252 - val_accuracy: 0.0000e+00 - val_loss: 682.0359\n",
      "Epoch 432/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2077 - loss: 1.4911 - val_accuracy: 0.0000e+00 - val_loss: 682.0348\n",
      "Epoch 433/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3814 - loss: 1.3461 - val_accuracy: 0.0000e+00 - val_loss: 682.0349\n",
      "Epoch 434/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2496 - loss: 1.3994 - val_accuracy: 0.0000e+00 - val_loss: 682.0326\n",
      "Epoch 435/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3680 - loss: 1.3860 - val_accuracy: 0.0000e+00 - val_loss: 682.0327\n",
      "Epoch 436/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4732 - loss: 1.0893 - val_accuracy: 0.0000e+00 - val_loss: 682.0312\n",
      "Epoch 437/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3704 - loss: 1.2611 - val_accuracy: 0.0000e+00 - val_loss: 682.0316\n",
      "Epoch 438/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4309 - loss: 1.2839 - val_accuracy: 0.0000e+00 - val_loss: 682.0298\n",
      "Epoch 439/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3084 - loss: 1.3896 - val_accuracy: 0.0000e+00 - val_loss: 682.0289\n",
      "Epoch 440/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3542 - loss: 1.3806 - val_accuracy: 0.0000e+00 - val_loss: 682.0270\n",
      "Epoch 441/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3002 - loss: 1.3111 - val_accuracy: 0.0000e+00 - val_loss: 682.0264\n",
      "Epoch 442/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4507 - loss: 1.3210 - val_accuracy: 0.0000e+00 - val_loss: 682.0247\n",
      "Epoch 443/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2895 - loss: 1.4756 - val_accuracy: 0.0000e+00 - val_loss: 682.0253\n",
      "Epoch 444/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3344 - loss: 1.3626 - val_accuracy: 0.0000e+00 - val_loss: 682.0225\n",
      "Epoch 445/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4224 - loss: 1.4133 - val_accuracy: 0.0000e+00 - val_loss: 682.0228\n",
      "Epoch 446/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2982 - loss: 1.3674 - val_accuracy: 0.0000e+00 - val_loss: 682.0203\n",
      "Epoch 447/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5125 - loss: 1.2234 - val_accuracy: 0.0000e+00 - val_loss: 682.0201\n",
      "Epoch 448/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1982 - loss: 1.5125 - val_accuracy: 0.0000e+00 - val_loss: 682.0184\n",
      "Epoch 449/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3502 - loss: 1.3478 - val_accuracy: 0.0000e+00 - val_loss: 682.0175\n",
      "Epoch 450/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3395 - loss: 1.4471 - val_accuracy: 0.0000e+00 - val_loss: 682.0167\n",
      "Epoch 451/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4214 - loss: 1.2815 - val_accuracy: 0.0000e+00 - val_loss: 682.0148\n",
      "Epoch 452/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4116 - loss: 1.1220 - val_accuracy: 0.0000e+00 - val_loss: 682.0132\n",
      "Epoch 453/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4590 - loss: 1.1650 - val_accuracy: 0.0000e+00 - val_loss: 682.0121\n",
      "Epoch 454/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3010 - loss: 1.3674 - val_accuracy: 0.0000e+00 - val_loss: 682.0116\n",
      "Epoch 455/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4696 - loss: 1.3526 - val_accuracy: 0.0000e+00 - val_loss: 682.0104\n",
      "Epoch 456/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3725 - loss: 1.3501 - val_accuracy: 0.0000e+00 - val_loss: 682.0095\n",
      "Epoch 457/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3401 - loss: 1.2899 - val_accuracy: 0.0000e+00 - val_loss: 682.0066\n",
      "Epoch 458/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3413 - loss: 1.2788 - val_accuracy: 0.0000e+00 - val_loss: 682.0059\n",
      "Epoch 459/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4933 - loss: 1.2881 - val_accuracy: 0.0000e+00 - val_loss: 682.0065\n",
      "Epoch 460/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4756 - loss: 1.1782 - val_accuracy: 0.0000e+00 - val_loss: 682.0040\n",
      "Epoch 461/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4347 - loss: 1.3464 - val_accuracy: 0.0000e+00 - val_loss: 682.0017\n",
      "Epoch 462/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3621 - loss: 1.3359 - val_accuracy: 0.0000e+00 - val_loss: 682.0013\n",
      "Epoch 463/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2897 - loss: 1.5030 - val_accuracy: 0.0000e+00 - val_loss: 682.0011\n",
      "Epoch 464/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2534 - loss: 1.4565 - val_accuracy: 0.0000e+00 - val_loss: 681.9977\n",
      "Epoch 465/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3836 - loss: 1.1653 - val_accuracy: 0.0000e+00 - val_loss: 681.9957\n",
      "Epoch 466/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4105 - loss: 1.2465 - val_accuracy: 0.0000e+00 - val_loss: 681.9955\n",
      "Epoch 467/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4511 - loss: 1.1058 - val_accuracy: 0.0000e+00 - val_loss: 681.9936\n",
      "Epoch 468/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4692 - loss: 1.1711 - val_accuracy: 0.0000e+00 - val_loss: 681.9916\n",
      "Epoch 469/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2787 - loss: 1.4337 - val_accuracy: 0.0000e+00 - val_loss: 681.9916\n",
      "Epoch 470/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4404 - loss: 1.2530 - val_accuracy: 0.0000e+00 - val_loss: 681.9894\n",
      "Epoch 471/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3009 - loss: 1.3602 - val_accuracy: 0.0000e+00 - val_loss: 681.9869\n",
      "Epoch 472/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3971 - loss: 1.3180 - val_accuracy: 0.0000e+00 - val_loss: 681.9871\n",
      "Epoch 473/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3309 - loss: 1.3938 - val_accuracy: 0.0000e+00 - val_loss: 681.9860\n",
      "Epoch 474/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4483 - loss: 1.2157 - val_accuracy: 0.0000e+00 - val_loss: 681.9821\n",
      "Epoch 475/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2776 - loss: 1.3826 - val_accuracy: 0.0000e+00 - val_loss: 681.9810\n",
      "Epoch 476/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4469 - loss: 1.3248 - val_accuracy: 0.0000e+00 - val_loss: 681.9816\n",
      "Epoch 477/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3075 - loss: 1.4109 - val_accuracy: 0.0000e+00 - val_loss: 681.9779\n",
      "Epoch 478/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2571 - loss: 1.4036 - val_accuracy: 0.0000e+00 - val_loss: 681.9764\n",
      "Epoch 479/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4210 - loss: 1.1905 - val_accuracy: 0.0000e+00 - val_loss: 681.9751\n",
      "Epoch 480/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3578 - loss: 1.3784 - val_accuracy: 0.0000e+00 - val_loss: 681.9734\n",
      "Epoch 481/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3354 - loss: 1.3284 - val_accuracy: 0.0000e+00 - val_loss: 681.9727\n",
      "Epoch 482/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3035 - loss: 1.4741 - val_accuracy: 0.0000e+00 - val_loss: 681.9717\n",
      "Epoch 483/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4777 - loss: 1.2713 - val_accuracy: 0.0000e+00 - val_loss: 681.9703\n",
      "Epoch 484/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4032 - loss: 1.3299 - val_accuracy: 0.0000e+00 - val_loss: 681.9662\n",
      "Epoch 485/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4168 - loss: 1.2112 - val_accuracy: 0.0000e+00 - val_loss: 681.9637\n",
      "Epoch 486/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3309 - loss: 1.3517 - val_accuracy: 0.0000e+00 - val_loss: 681.9637\n",
      "Epoch 487/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2605 - loss: 1.5033 - val_accuracy: 0.0000e+00 - val_loss: 681.9619\n",
      "Epoch 488/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3818 - loss: 1.2244 - val_accuracy: 0.0000e+00 - val_loss: 681.9594\n",
      "Epoch 489/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4308 - loss: 1.2228 - val_accuracy: 0.0000e+00 - val_loss: 681.9581\n",
      "Epoch 490/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3521 - loss: 1.3860 - val_accuracy: 0.0000e+00 - val_loss: 681.9569\n",
      "Epoch 491/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4648 - loss: 1.2616 - val_accuracy: 0.0000e+00 - val_loss: 681.9531\n",
      "Epoch 492/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3218 - loss: 1.3460 - val_accuracy: 0.0000e+00 - val_loss: 681.9528\n",
      "Epoch 493/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4370 - loss: 1.3300 - val_accuracy: 0.0000e+00 - val_loss: 681.9500\n",
      "Epoch 494/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4080 - loss: 1.3525 - val_accuracy: 0.0000e+00 - val_loss: 681.9487\n",
      "Epoch 495/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4498 - loss: 1.2327 - val_accuracy: 0.0000e+00 - val_loss: 681.9459\n",
      "Epoch 496/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3783 - loss: 1.2579 - val_accuracy: 0.0000e+00 - val_loss: 681.9441\n",
      "Epoch 497/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3820 - loss: 1.3392 - val_accuracy: 0.0000e+00 - val_loss: 681.9420\n",
      "Epoch 498/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3641 - loss: 1.2213 - val_accuracy: 0.0000e+00 - val_loss: 681.9398\n",
      "Epoch 499/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5073 - loss: 1.1220 - val_accuracy: 0.0000e+00 - val_loss: 681.9386\n",
      "Epoch 500/500\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3520 - loss: 1.3515 - val_accuracy: 0.0000e+00 - val_loss: 681.9365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f3f5db49180>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bean_tensors, bean_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "\n",
    "# Define the Keras model\n",
    "input_shape = (num_points_per_sample,)  # Assuming real and imaginary parts are concatenated\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(6, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # don't forget to change this to the number of classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3f5db61990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(cm, bean_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"classifier_coffee_3.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "\n",
    "dataset_path = 'session/group_0/entry_0/result/frame'\n",
    "\n",
    "# Define preprocessing functions\n",
    "def extract_tensor_from_h5(file_path, dataset_path):\n",
    "    \"\"\"\n",
    "    Extracts a tensor from an H5 file and checks for non-numerical data.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, path to the H5 file\n",
    "    - dataset_path: str, path to the dataset within the H5 file\n",
    "\n",
    "    Returns:\n",
    "    - tensor: numpy.ndarray, the extracted tensor if purely numerical\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as h5file:\n",
    "        if dataset_path in h5file:\n",
    "            dataset = h5file[dataset_path]\n",
    "            tensor = np.array(dataset)\n",
    "\n",
    "            return tensor\n",
    "        else:\n",
    "            raise KeyError(f\"Dataset {dataset_path} not found in the file {file_path}\")\n",
    "\n",
    "def preprocess_data(complex_tensor):\n",
    "    real_part = complex_tensor.real.astype(np.float32)\n",
    "    imag_part = complex_tensor.imag.astype(np.float32)\n",
    "    combined_input = np.concatenate([real_part, imag_part], axis=-1)\n",
    "    return combined_input\n",
    "\n",
    "def load_and_convert_tensor(file_path, dataset_path):\n",
    "    tensor = extract_tensor_from_h5(file_path, dataset_path)\n",
    "    complex_tensor = tensor['real'] + 1j * tensor['imag']\n",
    "    return complex_tensor\n",
    "\n",
    "def squeeze_data(data):\n",
    "    # Remove dimensions of size 1\n",
    "    return np.squeeze(data, axis=1)\n",
    "\n",
    "# Load and preprocess new data\n",
    "new_data_tensor = load_and_convert_tensor(\"sumatra_sample.h5\", dataset_path)\n",
    "new_data_input = preprocess_data(new_data_tensor)\n",
    "new_data_input = squeeze_data(new_data_input)\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('classifier_coffee_3.keras')\n",
    "print(\"Model loaded\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_data_input)\n",
    "predicted_classes = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# Print predictions\n",
    "sns.histplot(predicted_classes, discrete=True)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "\n",
    "dataset_path = 'session/group_0/entry_0/result/frame'\n",
    "\n",
    "# Define preprocessing functions\n",
    "def extract_tensor_from_h5(file_path, dataset_path):\n",
    "    \"\"\"\n",
    "    Extracts a tensor from an H5 file and checks for non-numerical data.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, path to the H5 file\n",
    "    - dataset_path: str, path to the dataset within the H5 file\n",
    "\n",
    "    Returns:\n",
    "    - tensor: numpy.ndarray, the extracted tensor if purely numerical\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as h5file:\n",
    "        if dataset_path in h5file:\n",
    "            dataset = h5file[dataset_path]\n",
    "            tensor = np.array(dataset)\n",
    "\n",
    "            return tensor\n",
    "        else:\n",
    "            raise KeyError(f\"Dataset {dataset_path} not found in the file {file_path}\")\n",
    "\n",
    "def preprocess_data(complex_tensor):\n",
    "    real_part = complex_tensor.real.astype(np.float32)\n",
    "    imag_part = complex_tensor.imag.astype(np.float32)\n",
    "    combined_input = np.concatenate([real_part, imag_part], axis=-1)\n",
    "    return combined_input\n",
    "\n",
    "def load_and_convert_tensor(file_path, dataset_path):\n",
    "    tensor = extract_tensor_from_h5(file_path, dataset_path)\n",
    "    complex_tensor = tensor['real'] + 1j * tensor['imag']\n",
    "    return complex_tensor\n",
    "\n",
    "def squeeze_data(data):\n",
    "    # Remove dimensions of size 1\n",
    "    return np.squeeze(data, axis=1)\n",
    "\n",
    "# Load and preprocess new data\n",
    "new_data_tensor = load_and_convert_tensor(\"peru_sample.h5\", dataset_path)\n",
    "new_data_input = preprocess_data(new_data_tensor)\n",
    "new_data_input = squeeze_data(new_data_input)\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('classifier_coffee_3.keras')\n",
    "print(\"Model loaded\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_data_input)\n",
    "predicted_classes = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# Print predictions\n",
    "sns.histplot(predicted_classes, discrete=True)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "\n",
    "dataset_path = 'session/group_0/entry_0/result/frame'\n",
    "\n",
    "# Define preprocessing functions\n",
    "def extract_tensor_from_h5(file_path, dataset_path):\n",
    "    \"\"\"\n",
    "    Extracts a tensor from an H5 file and checks for non-numerical data.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, path to the H5 file\n",
    "    - dataset_path: str, path to the dataset within the H5 file\n",
    "\n",
    "    Returns:\n",
    "    - tensor: numpy.ndarray, the extracted tensor if purely numerical\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as h5file:\n",
    "        if dataset_path in h5file:\n",
    "            dataset = h5file[dataset_path]\n",
    "            tensor = np.array(dataset)\n",
    "\n",
    "            return tensor\n",
    "        else:\n",
    "            raise KeyError(f\"Dataset {dataset_path} not found in the file {file_path}\")\n",
    "\n",
    "def preprocess_data(complex_tensor):\n",
    "    real_part = complex_tensor.real.astype(np.float32)\n",
    "    imag_part = complex_tensor.imag.astype(np.float32)\n",
    "    combined_input = np.concatenate([real_part, imag_part], axis=-1)\n",
    "    return combined_input\n",
    "\n",
    "def load_and_convert_tensor(file_path, dataset_path):\n",
    "    tensor = extract_tensor_from_h5(file_path, dataset_path)\n",
    "    complex_tensor = tensor['real'] + 1j * tensor['imag']\n",
    "    return complex_tensor\n",
    "\n",
    "def squeeze_data(data):\n",
    "    # Remove dimensions of size 1\n",
    "    return np.squeeze(data, axis=1)\n",
    "\n",
    "# Load and preprocess new data\n",
    "new_data_tensor = load_and_convert_tensor(\"colombia_sample.h5\", dataset_path)\n",
    "new_data_input = preprocess_data(new_data_tensor)\n",
    "new_data_input = squeeze_data(new_data_input)\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('classifier_coffee_3.keras')\n",
    "print(\"Model loaded\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(new_data_input)\n",
    "predicted_classes = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# Print predictions\n",
    "sns.histplot(predicted_classes, discrete=True)\n",
    "print(predicted_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
